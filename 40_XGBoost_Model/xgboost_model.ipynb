{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(xgboost)\n",
    "library(caret)\n",
    "library(MLmetrics)\n",
    "library(pROC)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(readxl)\n",
    "library(lubridate)\n",
    "library(car)\n",
    "library(haven)\n",
    "library(glmnet)\n",
    "library(tidyverse)\n",
    "library(haven)\n",
    "library(quantmod)\n",
    "library(timetk)\n",
    "library(glmnet)\n",
    "library(dplyr)\n",
    "library(tidyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the FDIC Data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data <- read_dta(\"~/Desktop/Fin Project/data2.dta\")\n",
    "# Add year, quarter, and date columns\n",
    "data <- data %>%\n",
    "mutate(\n",
    "year = as.numeric(substr(time, 1, 4)),\n",
    "quarter = as.numeric(substr(time, 6, 6)),\n",
    "date = case_when(\n",
    "quarter == 1 ~ as.Date(paste0(year, \"-01-01\")),\n",
    "quarter == 2 ~ as.Date(paste0(year, \"-04-01\")),\n",
    "quarter == 3 ~ as.Date(paste0(year, \"-07-01\")),\n",
    "quarter == 4 ~ as.Date(paste0(year, \"-10-01\"))\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Other Economic Indicators from FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get U.S. GDP and population data\n",
    "getSymbols(\"GDP\", src = \"FRED\") # Quarterly GDP (in billions)\n",
    "getSymbols(\"POP\", src = \"FRED\") # Total U.S. population\n",
    "# Interest rates\n",
    "getSymbols(\"FEDFUNDS\", src = \"FRED\")  # Federal Funds Rate, overnight interest rate set by the Fed\n",
    "getSymbols(\"MPRIME\", src = \"FRED\") # Prime Loan Rate\n",
    "getSymbols(\"GS10\", src = \"FRED\") # 10-Year Treasury Rate\n",
    "# Inflation and prices\n",
    "getSymbols(\"CPIAUCSL\", src = \"FRED\")# Consumer Price Index\n",
    "getSymbols(\"PCEPI\", src = \"FRED\") # Personal Consumption Expenditures Price Index\n",
    "getSymbols(\"PPIACO\", src = \"FRED\") # Producer Price Index\n",
    "# Economic growth\n",
    "getSymbols(\"INDPRO\", src = \"FRED\") # Industrial Production Index\n",
    "getSymbols(\"RSAFS\", src = \"FRED\") # Retail Sales\n",
    "getSymbols(\"TTLCONS\", src = \"FRED\") #Total Construction Spending\n",
    "# Labor market\n",
    "getSymbols(\"UNRATE\", src = \"FRED\")   # Unemployment Rate\n",
    "getSymbols(\"EMRATIO\", src = \"FRED\")   # Employment-Population Ratio\n",
    "getSymbols(\"PAYEMS\", src = \"FRED\") # Nonfarm Payrolls\n",
    "getSymbols(\"CIVPART\", src = \"FRED\")  # Labor Force Participation Rate\n",
    "# Money supply and banking\n",
    "getSymbols(\"M2SL\", src = \"FRED\")         # total money supply in circulation, including savings and time deposits\n",
    "getSymbols(\"TOTRESNS\", src = \"FRED\")     # Total Reserves held by banks\n",
    "getSymbols(\"BUSLOANS\", src = \"FRED\")     # Commercial and Industrial Loans\n",
    "getSymbols(\"REALLN\", src = \"FRED\")       # Consumer Loans\n",
    "# Sentiment\n",
    "getSymbols(\"UMCSENT\", src = \"FRED\")      # Consumer Sentiment Index\n",
    "# Financial markets\n",
    "getSymbols(\"SP500\", src = \"FRED\")        # S&P 500 Index\n",
    "getSymbols(\"DJIA\", src = \"FRED\")         # Dow Jones Industrial Average\n",
    "getSymbols(\"VIXCLS\", src = \"FRED\")       # Volatility Index\n",
    "# Housing market\n",
    "getSymbols(\"HOUST\", src = \"FRED\")        # Housing construction Starts\n",
    "getSymbols(\"CSUSHPINSA\", src = \"FRED\")   # Case-Shiller Home Price Index. tracks change in home prices over time\n",
    "getSymbols(\"EXHOSLUSM495S\", src = \"FRED\") # Existing Home Sales\n",
    "\n",
    "# Compute GDP per capita\n",
    "GDP_per_capita <- GDP / POP\n",
    "GDP_per_capita <- na.omit(GDP_per_capita)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging with main DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# List of FRED variables to merge\n",
    "fred_variables <- c(\n",
    "  \"FEDFUNDS\", \"MPRIME\", \"GS10\",\n",
    "  \"CPIAUCSL\", \"PCEPI\", \"PPIACO\", \"INDPRO\", \"RSAFS\", \"TTLCONS\",\n",
    "  \"UNRATE\", \"EMRATIO\", \"PAYEMS\", \"CIVPART\", \"M2SL\", \"TOTRESNS\",\n",
    "  \"BUSLOANS\", \"REALLN\", \"UMCSENT\", \"SP500\", \"DJIA\", \"VIXCLS\",\n",
    "  \"HOUST\", \"CSUSHPINSA\", \"EXHOSLUSM495S\"\n",
    ")\n",
    "\n",
    "# Loop over each FRED variable\n",
    "for (var in fred_variables) {\n",
    "  xts_data <- get(var)\n",
    "  df_data <- data.frame(date = index(xts_data), value = coredata(xts_data)) %>% as_tibble()\n",
    "  \n",
    "  df_data$date <- as.Date(df_data$date)\n",
    "  colnames(df_data)[2] <- var\n",
    "  \n",
    "  # Merge into 'data' dataframe\n",
    "  data <- data %>%\n",
    "    left_join(df_data, by = \"date\")\n",
    "}\n",
    "\n",
    "#For GDP per capita\n",
    "# Convert xts object to data frame\n",
    "GDP_per_capita_df <- data.frame(date = index(GDP_per_capita), GDP_per_capita = coredata(GDP_per_capita)) %>% as_tibble()\n",
    "# Merge GDP per capita into the dataset\n",
    "data <- data %>%\n",
    "left_join(GDP_per_capita_df, by = \"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Remove columns with excessive missing values\n",
    "na_counts <- colSums(is.na(data))\n",
    "columns_to_remove <- names(na_counts[na_counts > 20])\n",
    "data <- data %>% select(-all_of(columns_to_remove))\n",
    "# Handle remaining missing values\n",
    "data_nonNA <- na.omit(data)\n",
    "# Remove non-numerical columns\n",
    "data_nonNA <- data_nonNA %>% select(-time, -date)\n",
    "if (class(data_nonNA$deposits) == \"list\") {\n",
    "data_nonNA$deposits <- as.numeric(unlist(data_nonNA$deposits))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Feature Engineering\n",
    "\n",
    "### Feature Selection - Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define the list of predictors after dropping NAs\n",
    "predictors <- c(\n",
    "  \"FEDFUNDS\", \"MPRIME\", \"GS10\",\n",
    "  \"CPIAUCSL\", \"PCEPI\", \"PPIACO\", \"INDPRO\",\n",
    "  \"UNRATE\", \"EMRATIO\", \"PAYEMS\", \"CIVPART\", \"M2SL\", \"TOTRESNS\",\n",
    "  \"BUSLOANS\", \"REALLN\", \"UMCSENT\",\n",
    "  \"HOUST\", \"CSUSHPINSA\", \"GDP\"\n",
    ")\n",
    "\n",
    "# Prepare the predictor matrix and response vector\n",
    "X <- data %>% select(all_of(predictors))\n",
    "y <- data$deposits\n",
    "# Convert to matrices\n",
    "X_matrix <- as.matrix(X)\n",
    "y_vector <- as.numeric(y)\n",
    "# Handle missing values\n",
    "complete_cases <- complete.cases(X_matrix, y_vector)\n",
    "X_matrix <- X_matrix[complete_cases, ]\n",
    "y_vector <- y_vector[complete_cases]\n",
    "\n",
    "# Get the number of observations\n",
    "n_obs <- nrow(X_matrix)\n",
    "# Define the number of folds\n",
    "n_folds <- 5\n",
    "\n",
    "# Create fold IDs that increase over time\n",
    "fold_size <- floor(n_obs / n_folds)\n",
    "foldid <- rep(1:n_folds, each = fold_size)\n",
    "# Adjust for any remaining observations\n",
    "if (length(foldid) < n_obs) {\n",
    "  foldid <- c(foldid, rep(n_folds, n_obs - length(foldid)))\n",
    "}\n",
    "# Verify foldid length\n",
    "if (length(foldid) != n_obs) {\n",
    "  stop(\"Fold ID length does not match the number of observations.\")\n",
    "}\n",
    "# Set seed for reproducibility\n",
    "set.seed(123)\n",
    "\n",
    "# Perform cross-validation with custom fold IDs\n",
    "cv_lasso <- cv.glmnet(\n",
    "  x = X_matrix,\n",
    "  y = y_vector,\n",
    "  alpha = 1,\n",
    "  nfolds = n_folds,\n",
    "  foldid = foldid,\n",
    "  standardize = TRUE,\n",
    "  type.measure = \"mse\"\n",
    ")\n",
    "\n",
    "# Optimal lambda\n",
    "lambda_min <- cv_lasso$lambda.min #this retrieves lambda\n",
    "lambda_1se <- cv_lasso$lambda.1se #Retrieves the largest value of lambda such that the cross-validated error is within one standard error of the minimum MSE\n",
    "cat(\"Lambda minimizing MSE (lambda.min):\", lambda_min, \"\\n\")\n",
    "cat(\"Lambda within 1 SE of min MSE (lambda.1se):\", lambda_1se, \"\\n\")\n",
    "\n",
    "# Extract coefficients at lambda.min\n",
    "coef_min <- coef(cv_lasso, s = \"lambda.min\")\n",
    "\n",
    "# Convert coefficients to data frame\n",
    "coef_df <- as.data.frame(as.matrix(coef_min))\n",
    "coef_df <- coef_df %>% mutate(predictor = rownames(coef_df))\n",
    "colnames(coef_df)[1] <- \"coefficient\"\n",
    "\n",
    "# Exclude the intercept\n",
    "coef_df <- coef_df %>% filter(predictor != \"(Intercept)\")\n",
    "\n",
    "# Identify non-zero coefficients\n",
    "selected_predictors <- coef_df %>% filter(coefficient >1)\n",
    "\n",
    "# Print selected predictors\n",
    "cat(\"Predictors selected by Lasso regression at lambda.min:\\n\")\n",
    "print(selected_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "predictors9 <- c(\n",
    "  \"MPRIME\", \"PPIACO\", \"INDPRO\", \"EMRATIO\", \"BUSLOANS\", \"REALLN\", \"UMCSENT\", \"HOUST\", \"CSUSHPINSA\"\n",
    ")\n",
    "\n",
    "# predictors6 <- c(\n",
    "#   \"MPRIME\", \"PPIACO\", \"INDPRO\", \"EMRATIO\", \"BUSLOANS\", \"REALLN\"\n",
    "# )\n",
    "# \n",
    "# predictors3 <- c(\n",
    "#   \"MPRIME\", \"PPIACO\", \"INDPRO\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lags\n",
    "\n",
    "### Create lags for deposits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create lagged features for the 'deposits' column with only 3 lags\n",
    "lagged_data <- tk_augment_lags(data_nonNA, .value = deposits, .lags = 1:5)\n",
    "\n",
    "# Remove rows with NAs (due to lags)\n",
    "lagged_data <- na.omit(lagged_data)\n",
    "\n",
    "# Define lagged columns for 3 lags\n",
    "#lagged_cols <- paste0(\"deposits_lag\", 1:5)\n",
    "lagged_cols <- paste0(\"deposits_lag\", 1:3)\n",
    "\n",
    "# Convert lagged columns to numeric if necessary\n",
    "for (col in lagged_cols) {\n",
    "  if (class(lagged_data[[col]]) == \"list\") {\n",
    "    lagged_data[[col]] <- as.numeric(unlist(lagged_data[[col]]))\n",
    "  } else {\n",
    "    lagged_data[[col]] <- as.numeric(lagged_data[[col]])\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating lags for predictors (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define the predictors you want to lag\n",
    "predictors_to_lag <- predictors9\n",
    "\n",
    "# Convert predictors to numeric if necessary\n",
    "for (col in predictors_to_lag) {\n",
    "  lagged_data[[col]] <- as.numeric(lagged_data[[col]])\n",
    "}\n",
    "lags <- 1:5\n",
    "lagged_data <- lagged_data %>%\n",
    "  tk_augment_lags(.value = predictors_to_lag, .lags = lags)\n",
    "\n",
    "# Create a vector of lagged predictor column names\n",
    "lagged_predictor_cols <- expand.grid(predictors_to_lag, lags) %>%\n",
    "  mutate(lagged_col = paste0(Var1, \"_lag\", Var2)) %>%\n",
    "  pull(lagged_col)\n",
    "\n",
    "# Convert lagged predictor columns to numeric\n",
    "for (col in lagged_predictor_cols) {\n",
    "  lagged_data[[col]] <- as.numeric(lagged_data[[col]])\n",
    "}\n",
    "# Remove rows with NAs (due to lagging)\n",
    "lagged_data <- na.omit(lagged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#predictor_cols <- c(lagged_cols, predictors9)  # Adjust for your predictors\n",
    "predictor_cols <- c(lagged_cols)  # Adjust for your predictors\n",
    "\n",
    "# Assuming your data is ordered by time\n",
    "split_index <- floor(0.8 * nrow(lagged_data))\n",
    "train_data <- lagged_data[1:split_index, ]\n",
    "test_data <- lagged_data[(split_index + 1):nrow(lagged_data), ]\n",
    "\n",
    "# Training set\n",
    "x_train <- train_data[, predictor_cols]\n",
    "y_train <- train_data$deposits\n",
    "\n",
    "# Test set\n",
    "x_test <- test_data[, predictor_cols]\n",
    "y_test <- test_data$deposits\n",
    "\n",
    "#####\n",
    "# Define predictor columns and target variable\n",
    "#predictor_cols <- c(lagged_cols, predictors9)  # Adjust for your predictors\n",
    "#x_data <- lagged_data[, predictor_cols]\n",
    "#y_data <- lagged_data$deposits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Normalising and Scaling (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Convert predictors and target to matrices and numeric vectors\n",
    "# Scale predictors\n",
    "#x_train_scaled <- scale(x_train)\n",
    "x_train_scaled <- (x_train)\n",
    "# Apply the same transformation to test data\n",
    "#x_test_scaled <- scale(x_test, center = attr(x_train_scaled, \"scaled:center\"), scale = attr(x_train_scaled, \"scaled:scale\"))\n",
    "x_test_scaled <- x_test\n",
    "# Convert to data frames\n",
    "x_train_scaled <- as.data.frame(x_train_scaled)\n",
    "x_test_scaled <- as.data.frame(x_test_scaled)\n",
    "\n",
    "# Prepare DMatrix for training and validation\n",
    "dtrain <- xgb.DMatrix(data = as.matrix(x_train_scaled), label = y_train)\n",
    "dtest <- xgb.DMatrix(data = as.matrix(x_test_scaled), label = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. XGBOOST\n",
    "\n",
    "-   Time series cross validation is used to split the data into multiple training and test sets\n",
    "-   Cross validation\n",
    "-   Evaluates models across all splits\n",
    "-   Hyperparameter tuning grid\n",
    "\n",
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define time series cross-validation strategy\n",
    "time_control <- trainControl(\n",
    "  method = \"timeslice\",\n",
    "  initialWindow = 80,        # Initial training window (e.g., 80 time steps)\n",
    "  horizon = 8,           # Testing window size (e.g., next 20 time steps)\n",
    "  fixedWindow = FALSE,        # Sliding window\n",
    "  savePredictions = \"final\", # Save final predictions for analysis\n",
    "  verboseIter = FALSE       # Print messages or not\n",
    ")\n",
    "\n",
    "# Train the XGBoost model with caret\n",
    "xgb_grid <- expand.grid(\n",
    "  nrounds = c(100,200,300),           # Number of boosting rounds\n",
    "  max_depth = c(3,5,7,10),           # Tree depth\n",
    "  eta = c(0.01,0.05,0.3),               # Learning rate\n",
    "  gamma = c(0.1, 1, 5),              # Regularization parameter\n",
    "  colsample_bytree = c(0.8, 1),  # Column sampling. The fraction of features that are randomly sampled for each tree. Reducing this value can help prevent overfitting. 1 - uses all features for each tree.\n",
    "  min_child_weight = 1,    # Minimum child weight. specifies the min sum of the weights of all observations required in a leaf node. Higher value makes the model more conservative by requiring more observations to form a leaf. (can prevent overfitting). 1 means theres no restriction on the sum of weights for forming a leaf node. \n",
    "  subsample = c(0.8, 1)          # Row sampling. The fraction of the training data that is randomly sampled to grow each tree (0-1). 1 uses all training data for each tree (no sampling)\n",
    ")\n",
    "\n",
    "# xgb_model_1 <- train(\n",
    "#   x = x_data_matrix,\n",
    "#   y = y_data_vector,\n",
    "#   method = \"xgbTree\",       # XGBoost method in caret\n",
    "#   trControl = time_control, # Time series cross-validation\n",
    "#   tuneGrid = xgb_grid       # Hyperparameter grid\n",
    "# )\n",
    "\n",
    "xgb_model_1 <- train(\n",
    "  x = as.matrix(x_train_scaled),\n",
    "  y = y_train,\n",
    "  method = \"xgbTree\",\n",
    "  trControl = time_control,\n",
    "  tuneGrid = xgb_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "best_tune <- xgb_model_1$bestTune\n",
    "best_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best tune with xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define watchlist to monitor training and validation errors\n",
    "watchlist <- list(train = dtrain, eval = dtest)\n",
    "params <- list(\n",
    "  objective = \"reg:squarederror\",\n",
    "  max_depth = best_tune$max_depth,\n",
    "  eta = best_tune$eta,\n",
    "  gamma = best_tune$gamma,\n",
    "  colsample_bytree = best_tune$colsample_bytree,\n",
    "  min_child_weight = best_tune$min_child_weight,\n",
    "  subsample = best_tune$subsample\n",
    ")\n",
    "xgb_model <- xgb.train(\n",
    "  params = params,\n",
    "  data = dtrain,\n",
    "  nrounds = best_tune$nrounds,\n",
    "  watchlist = watchlist,\n",
    "  eval_metric = \"rmse\",\n",
    "  verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation\n",
    "\n",
    "### Train - Validation Metrics - RMSE, R2, MAE, MASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extract evaluation log\n",
    "eval_log <- xgb_model$evaluation_log\n",
    "\n",
    "# Compute additional metrics (MAE, MASE, R²)\n",
    "eval_log <- eval_log %>%\n",
    "  mutate(\n",
    "    train_mae = abs(train_rmse), # Placeholder: Replace with true train_mae if available\n",
    "    eval_mae = abs(eval_rmse),   # Placeholder: Replace with true eval_mae if available\n",
    "    train_r2 = 1 - (train_rmse^2 / var(y_train)), # R² approximation\n",
    "    eval_r2 = 1 - (eval_rmse^2 / var(y_test)),    # R² approximation\n",
    "    train_mase = train_mae / mean(abs(diff(y_train))),\n",
    "    eval_mase = eval_mae / mean(abs(diff(y_test)))\n",
    "  )\n",
    "\n",
    "# Plot training and validation RMSE over iterations\n",
    "ggplot(eval_log, aes(x = iter)) +\n",
    "  geom_line(aes(y = train_rmse, color = \"Training RMSE\")) +\n",
    "  geom_line(aes(y = eval_rmse, color = \"Validation RMSE\")) +\n",
    "  labs(\n",
    "    title = \"Training and Validation RMSE over Iterations\",\n",
    "    x = \"Iteration\",\n",
    "    y = \"RMSE\"\n",
    "  ) +\n",
    "  scale_color_manual(\n",
    "    \"\",\n",
    "    breaks = c(\"Training RMSE\", \"Validation RMSE\"),\n",
    "    values = c(\"blue\", \"red\")\n",
    "  ) +\n",
    "  theme_minimal()\n",
    "\n",
    "# Plot MAE\n",
    "ggplot(eval_log, aes(x = iter)) +\n",
    "  geom_line(aes(y = train_mae, color = \"Training MAE\")) +\n",
    "  geom_line(aes(y = eval_mae, color = \"Validation MAE\")) +\n",
    "  labs(\n",
    "    title = \"Training and Validation MAE over Iterations\",\n",
    "    x = \"Iteration\",\n",
    "    y = \"MAE\"\n",
    "  ) +\n",
    "  scale_color_manual(\"\", breaks = c(\"Training MAE\", \"Validation MAE\"), values = c(\"blue\", \"red\")) +\n",
    "  theme_minimal()\n",
    "\n",
    "# Plot R²\n",
    "ggplot(eval_log, aes(x = iter)) +\n",
    "  geom_line(aes(y = train_r2, color = \"Training R²\")) +\n",
    "  geom_line(aes(y = eval_r2, color = \"Validation R²\")) +\n",
    "  labs(\n",
    "    title = \"Training and Validation R² over Iterations\",\n",
    "    x = \"Iteration\",\n",
    "    y = \"R²\"\n",
    "  ) +\n",
    "  scale_color_manual(\"\", breaks = c(\"Training R²\", \"Validation R²\"), values = c(\"blue\", \"red\")) +\n",
    "  theme_minimal()\n",
    "\n",
    "# Plot MASE\n",
    "ggplot(eval_log, aes(x = iter)) +\n",
    "  geom_line(aes(y = train_mase, color = \"Training MASE\")) +\n",
    "  geom_line(aes(y = eval_mase, color = \"Validation MASE\")) +\n",
    "  labs(\n",
    "    title = \"Training and Validation MASE over Iterations\",\n",
    "    x = \"Iteration\",\n",
    "    y = \"MASE\"\n",
    "  ) +\n",
    "  scale_color_manual(\"\", breaks = c(\"Training MASE\", \"Validation MASE\"), values = c(\"blue\", \"red\")) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test - Evaluation Metrics (xgb_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions_test <- predict(xgb_model_1, newdata = as.matrix(x_test_scaled))\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "test_rmse <- RMSE(predictions_test, y_test)\n",
    "test_mae <- MAE(predictions_test, y_test)\n",
    "test_r2 <- R2(predictions_test, y_test)\n",
    "\n",
    "cat(\"Test RMSE:\", test_rmse, \"\\n\")\n",
    "cat(\"Test MAE:\", test_mae, \"\\n\")\n",
    "cat(\"Test R²:\", test_r2, \"\\n\")\n",
    "\n",
    "# Calculate naive forecasts (lag 1)\n",
    "naive_forecasts <- c(NA, y_test[-length(y_test)])\n",
    "\n",
    "# Remove NA values for alignment\n",
    "actual_values <- y_test[-1]\n",
    "predicted_values <- predictions_test[-1]\n",
    "naive_values <- naive_forecasts[-1]\n",
    "\n",
    "# Calculate MAE for the model and naive forecast\n",
    "mae_model <- mean(abs(actual_values - predicted_values))\n",
    "mae_naive <- mean(abs(actual_values - naive_values))\n",
    "\n",
    "# Compute MASE\n",
    "test_mase <- mae_model / mae_naive\n",
    "print(paste(\"Test Mean Absolute Scaled Error (MASE):\", round(test_mase, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test - Evaluation Metrics (xgb_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set using xgb_model\n",
    "predictions_test <- predict(xgb_model, newdata = dtest)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "test_rmse <- sqrt(mean((predictions_test - y_test)^2)) # RMSE\n",
    "test_mae <- mean(abs(predictions_test - y_test))       # MAE\n",
    "test_r2 <- 1 - (sum((y_test - predictions_test)^2) / sum((y_test - mean(y_test))^2)) # R²\n",
    "\n",
    "# Print evaluation metrics\n",
    "cat(\"Test RMSE:\", round(test_rmse, 4), \"\\n\")\n",
    "cat(\"Test MAE:\", round(test_mae, 4), \"\\n\")\n",
    "cat(\"Test R²:\", round(test_r2, 4), \"\\n\")\n",
    "\n",
    "# Calculate naive forecasts (lag 1)\n",
    "#naive_forecasts <- c(NA, y_test[-length(y_test)]) # Shift y_test by one timestep\n",
    "\n",
    "# Remove NA values for alignment\n",
    "#actual_values <- y_test[-1]\n",
    "#predicted_values <- predictions_test[-1]\n",
    "#naive_values <- naive_forecasts[-1]\n",
    "\n",
    "# Calculate MAE for the model and naive forecast\n",
    "#mae_model <- mean(abs(actual_values - predicted_values))\n",
    "#mae_naive <- mean(abs(actual_values - naive_values))\n",
    "\n",
    "# Compute MASE\n",
    "#test_mase <- mae_model / mae_naive\n",
    "#cat(\"Test Mean Absolute Scaled Error (MASE):\", round(test_mase, 4), \"\\n\")\n",
    "\n",
    "mase <- function(y_train, y_test, y_preds) {\n",
    "  n <- length(y_train)\n",
    "  m <- length(y_test)\n",
    "  # Calculate the denominator (scaled error from y_train)\n",
    "  denom <- 0\n",
    "  for (i in 1:(n - m)) {\n",
    "    # Compute the mean absolute difference for the m-length window\n",
    "    denom <- denom + mean(abs(y_train[(i + 1):(i + m)] - rep(y_train[i], m)))\n",
    "  }\n",
    "  denom <- denom / (n - m)\n",
    "  # Calculate the numerator (mean absolute error for predictions)\n",
    "  num <- mean(abs(y_test - y_preds))\n",
    "  # Return the MASE\n",
    "  return(num / denom)\n",
    "}\n",
    "# Calculate MASE\n",
    "mase_value <- mase(y_train, y_test, predicted_values)\n",
    "\n",
    "# Print the result\n",
    "cat(\"Mean Absolute Scaled Error (MASE):\", round(mase_value, 4), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualisation\n",
    "\n",
    "### Actual vs Predicted Deposits\n",
    "\n",
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "train_predictions <- predict(xgb_model, newdata = dtrain)\n",
    "\n",
    "# Define a sequence of dates for the training data, starting from a specific date\n",
    "start_date <- as.Date(\"1996-07-01\")  # Adjust this to your actual start date\n",
    "dates <- seq(from = start_date, by = \"quarter\", length.out = length(y_train))\n",
    "\n",
    "# Create the data frame for training visualization with Date instead of Index\n",
    "results_train <- data.frame(\n",
    "  Date = dates,\n",
    "  Actual = y_train,\n",
    "  Predicted = train_predictions\n",
    ")\n",
    "\n",
    "# Plot actual vs predicted for training data\n",
    "ggplot(results_train, aes(x = Date)) +\n",
    "  geom_line(aes(y = Actual, color = \"Actual\"), size = 1) +\n",
    "  geom_line(aes(y = Predicted, color = \"Predicted\"), linetype = \"dashed\", size = 1) +\n",
    "  labs(\n",
    "    title = \"Actual vs Predicted Deposits (Training)\",\n",
    "    x = \"Dates\",\n",
    "    y = \"Deposits\"\n",
    "  ) +\n",
    "  scale_color_manual(\n",
    "    name = \"\",\n",
    "    breaks = c(\"Actual\", \"Predicted\"),\n",
    "    values = c(\"blue\", \"red\")\n",
    "  ) +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    legend.position = \"top\",\n",
    "    legend.title = element_blank(),\n",
    "    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n",
    "    axis.title = element_text(size = 12),\n",
    "    axis.text = element_text(size = 10)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "``{r}\n",
    "# Predict on test data\n",
    "test_predictions <- predict(xgb_model, newdata = dtest)\n",
    "\n",
    "# Create a data frame for test visualization\n",
    "start_date <- as.Date(\"2019-01-01\")  # Adjust this to your actual start date\n",
    "dates <- seq(from = start_date, by = \"quarter\", length.out = length(y_test))\n",
    "\n",
    "results_test <- data.frame(\n",
    "  Date = dates,\n",
    "  Actual = y_test,\n",
    "  Predicted = test_predictions\n",
    ")\n",
    "\n",
    "# Plot actual vs predicted for test data\n",
    "ggplot(results_test, aes(x = Date)) +\n",
    "  geom_line(aes(y = Actual, color = \"Actual\"), size = 1) +\n",
    "  geom_line(aes(y = Predicted, color = \"Predicted\"), linetype = \"dashed\", size = 1) +\n",
    "  labs(\n",
    "    title = \"Actual vs Predicted Deposits (Test Data)\",\n",
    "    x = \"Index\",\n",
    "    y = \"Deposits\"\n",
    "  ) +\n",
    "  scale_color_manual(\n",
    "    name = \"\",\n",
    "    breaks = c(\"Actual\", \"Predicted\"),\n",
    "    values = c(\"blue\", \"red\")\n",
    "  ) +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    legend.position = \"top\",\n",
    "    legend.title = element_blank(),\n",
    "    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n",
    "    axis.title = element_text(size = 12),\n",
    "    axis.text = element_text(size = 10)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Add a column to indicate the data type (Train/Test)\n",
    "results_train$Type <- \"Train\"\n",
    "results_test$Type <- \"Test\"\n",
    "\n",
    "# Combine train and test data\n",
    "results_combined <- rbind(results_train, results_test)\n",
    "\n",
    "# Print the combined dataframe\n",
    "print(results_combined)\n",
    "\n",
    "# Plot actual vs predicted for both train and test data\n",
    "ggplot(results_combined, aes(x = Date, y = Actual, color = Type)) +\n",
    "  geom_line(size = 1) +\n",
    "  geom_line(aes(y = Predicted, linetype = Type), size = 1) +\n",
    "  labs(\n",
    "    title = \"Actual vs Predicted Deposits (Train and Test Data)\",\n",
    "    x = \"Date\",\n",
    "    y = \"Deposits\"\n",
    "  ) +\n",
    "  scale_color_manual(\n",
    "    name = \"Dataset\",\n",
    "    breaks = c(\"Train\", \"Test\"),\n",
    "    values = c(\"blue\", \"red\")\n",
    "  ) +\n",
    "  scale_linetype_manual(\n",
    "    name = \"Prediction\",\n",
    "    breaks = c(\"Train\", \"Test\"),\n",
    "    values = c(\"solid\", \"dashed\")\n",
    "  ) +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    legend.position = \"top\",\n",
    "    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n",
    "    axis.title = element_text(size = 12),\n",
    "    axis.text = element_text(size = 10)\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Feature Importance\n",
    "\n",
    "### Feature plot for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_matrix <- xgb.importance(model = xgb_model)\n",
    "\n",
    "# Print feature importance\n",
    "print(importance_matrix)\n",
    "\n",
    "# Plot feature importance\n",
    "xgb.plot.importance(importance_matrix, measure = \"Gain\") +\n",
    "  labs(\n",
    "    title = \"Top 10 Features by Importance (Gain)\"\n",
    "  ) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature plot for xgb1 (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "var_imp <- varImp(xgb_model_1)\n",
    "print(var_imp)\n",
    "plot(var_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create the initial dataframe with the 2024 Q4 lag values\n",
    "recession_test <- data.frame(\n",
    "  deposits_lag1 = 349452.05,\n",
    "  deposits_lag2 = 353246.44,\n",
    "  deposits_lag3 = 352951.20\n",
    ")\n",
    "\n",
    "# Define the quarterly sequence starting from 2024 Q4 to 2028 Q4\n",
    "forecast_quarters <- seq(from = as.Date(\"2024-10-01\"), by = \"quarter\", length.out = 20)\n",
    "\n",
    "# Initialize a dataframe to store predictions\n",
    "forecast <- data.frame(Quarter = character(0), Predicted_Deposit = numeric(0))\n",
    "\n",
    "# Iterate for each quarter in the sequence\n",
    "for (i in 1:length(forecast_quarters)) {\n",
    "  # Create a DMatrix for prediction\n",
    "  recession_dmatrix <- xgb.DMatrix(data = as.matrix(recession_test))\n",
    "  \n",
    "  # Predict the value\n",
    "  recession_prediction <- predict(xgb_model, newdata = recession_dmatrix)\n",
    "  \n",
    "  # Append the prediction to the forecast dataframe\n",
    "  forecast <- rbind(forecast, data.frame(\n",
    "    Quarter = format(forecast_quarters[i], \"%Y Q%q\"),\n",
    "    Predicted_Deposit = recession_prediction\n",
    "  ))\n",
    "  \n",
    "  # Update the lag values\n",
    "  recession_test <- data.frame(\n",
    "    deposits_lag1 = recession_test$deposits_lag2,\n",
    "    deposits_lag2 = recession_test$deposits_lag3,\n",
    "    deposits_lag3 = recession_prediction\n",
    "  )\n",
    "}\n",
    "\n",
    "# Convert Quarter to factor to ensure proper order in the plot\n",
    "forecast$Quarter <- factor(forecast$Quarter, levels = unique(forecast$Quarter))\n",
    "\n",
    "# Print the forecast dataframe\n",
    "print(forecast)\n",
    "\n",
    "# Visualize the results (e.g., using ggplot2)\n",
    "library(ggplot2)\n",
    "ggplot(forecast, aes(x = Quarter, y = Predicted_Deposit)) +\n",
    "  geom_line(aes(group = 1)) +\n",
    "  geom_point() +\n",
    "  theme_minimal() +\n",
    "  labs(title = \"Forecasted Deposits (2024 Q4 - 2028 Q4)\",\n",
    "       x = \"Quarter\",\n",
    "       y = \"Predicted Deposit\") +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Forecast Data\n",
    "# Define the initial values for forecasting\n",
    "recession_test <- data.frame(\n",
    "  deposits_lag1 = 349452.05,\n",
    "  deposits_lag2 = 353246.44,\n",
    "  deposits_lag3 = 352951.20\n",
    ")\n",
    "\n",
    "# Define the quarterly sequence for forecasting\n",
    "forecast_quarters <- seq(from = as.Date(\"2024-10-01\"), by = \"quarter\", length.out = 20)\n",
    "\n",
    "# Initialize a dataframe to store forecast data\n",
    "forecast <- data.frame(\n",
    "  Date = forecast_quarters,\n",
    "  Predicted = rep(NA, length(forecast_quarters)),  # Initialize with NA\n",
    "  Type = rep(\"Forecast\", length(forecast_quarters))  # Match rows with Date\n",
    ")\n",
    "\n",
    "# Iterate to forecast values\n",
    "# Iterate to forecast values\n",
    "for (i in 1:length(forecast_quarters)) {\n",
    "  # Create a DMatrix for prediction\n",
    "  recession_dmatrix <- xgb.DMatrix(data = as.matrix(recession_test))\n",
    "  \n",
    "  # Predict the value\n",
    "  recession_prediction <- predict(xgb_model, newdata = recession_dmatrix)\n",
    "  \n",
    "  # Update the `Predicted` column of the `forecast` dataframe\n",
    "  forecast$Predicted[i] <- recession_prediction\n",
    "  \n",
    "  # Update lag values\n",
    "  recession_test <- data.frame(\n",
    "    deposits_lag1 = recession_test$deposits_lag2,\n",
    "    deposits_lag2 = recession_test$deposits_lag3,\n",
    "    deposits_lag3 = recession_prediction\n",
    "  )\n",
    "}\n",
    "\n",
    "# Add Actual column to Forecast (set to NA since it's unknown)\n",
    "forecast$Actual <- NA\n",
    "\n",
    "# 3. Combine All Data\n",
    "all_data <- rbind(results_combined, forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure proper ordering by Date\n",
    "all_data <- all_data[order(all_data$Date), ]\n",
    "\n",
    "# Plot Actual vs Predicted for Train, Test, and Forecast\n",
    "ggplot(all_data, aes(x = Date)) +\n",
    "  # Plot Actual values (exclude rows where Actual is NA)\n",
    "  geom_line(aes(y = Actual, color = Type, linetype = \"Actual\"), size = 0.5, na.rm = TRUE) +\n",
    "  # Plot Predicted values\n",
    "  geom_line(aes(y = Predicted, color = Type, linetype = \"Predicted\"), size = 0.9) +\n",
    "  # Customize labels and legends\n",
    "  labs(\n",
    "    title = \"Actual vs Predicted Deposits (Train, Test, and Forecast)\",\n",
    "    x = \"Date\",\n",
    "    y = \"Deposits (in Millions)\"\n",
    "  ) +\n",
    "  # Customize colors for Train, Test, and Forecast\n",
    "  scale_color_manual(\n",
    "    name = \"Dataset\",\n",
    "    values = c(\"Train\" = \"blue\", \"Test\" = \"red\", \"Forecast\" = \"green\")\n",
    "  ) +\n",
    "  # Customize linetypes for Actual and Predicted\n",
    "  scale_linetype_manual(\n",
    "    name = \"Legend\",\n",
    "    values = c(\"Actual\" = \"solid\", \"Predicted\" = \"twodash\")\n",
    "  ) +\n",
    "  # Adjust y-axis to display values in millions\n",
    "  scale_y_continuous(\n",
    "    labels = function(x) paste0(x / 1e6, \"M\")  # Convert to millions and add \"M\"\n",
    "  ) +\n",
    "  # Minimal theme for clarity\n",
    "  theme_classic() +\n",
    "  theme(\n",
    "    legend.position = \"top\",\n",
    "    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n",
    "    axis.title = element_text(size = 12),\n",
    "    axis.text = element_text(size = 10)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2025 Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Forecast\n",
    "# Create the dataframe in R - values for 2024q4\n",
    "recession_test <- data.frame(\n",
    "  deposits_lag1 = 349452.05,\n",
    "  deposits_lag2 = 353246.44,\n",
    "  deposits_lag3 = 352951.20,\n",
    "  deposits_lag4 = 361265.55,\n",
    "  deposits_lag5 = 361428.41,\n",
    "  MPRIME = 8.50,\n",
    "  PPIACO = 256.978,\n",
    "  INDPRO = 102.3568,\n",
    "  EMRATIO = 60.2,\n",
    "  BUSLOANS = 2750.5599,\n",
    "  REALLN = 5601.8193,\n",
    "  UMCSENT = 77.2,\n",
    "  HOUST = 1377,\n",
    "  CSUSHPINSA = 320.883\n",
    ")\n",
    "\n",
    "#recession_test <- tail(x_test_scaled, 4)\n",
    "recession_dmatrix <- xgb.DMatrix(data = as.matrix(recession_test))\n",
    "recession_predictions <- predict(xgb_model, newdata = recession_dmatrix)\n",
    "\n",
    "# Get the predicted value for a single data point (e.g., the first row)\n",
    "cat(\"Predicted Deposit (Recession):\", recession_predictions, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
